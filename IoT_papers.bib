
@incollection{ji_recprov:_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{RecProv}: {Towards} {Provenance}-{Aware} {User} {Space} {Record} and {Replay}},
	copyright = {©2016 Springer International Publishing Switzerland},
	isbn = {978-3-319-40592-6 978-3-319-40593-3},
	shorttitle = {{RecProv}},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-40593-3_1},
	abstract = {Deterministic record and replay systems have widely been used in software debugging, failure diagnosis, and intrusion detection. In order to detect the Advanced Persistent Threat (APT), online execution needs to be recorded with acceptable runtime overhead; then, investigators can analyze the replayed execution with heavy dynamic instrumentation. While most record and replay systems rely on kernel module or OS virtualization, those running at user space are favoured for being lighter weight and more portable without any of the changes needed for OS/Kernel virtualization. On the other hand, higher level provenance data at a higher level provides dynamic analysis with system causalities and hugely increases its efficiency. Considering both benefits, we propose a provenance-aware user space record and replay system, called RecProv. RecProv is designed to provide high provenance fidelity; specifically, with versioning files from the recorded trace logs and integrity protection to provenance data through real-time trace isolation. The collected provenance provides the high-level system dependency that helps pinpoint suspicious activities where further analysis can be applied. We show that RecProv is able to output accurate provenance in both visualized graph and W3C standardized PROV-JSON formats.},
	language = {en},
	number = {9672},
	urldate = {2016-09-15},
	booktitle = {Provenance and {Annotation} of {Data} and {Processes}},
	publisher = {Springer International Publishing},
	author = {Ji, Yang and Lee, Sangho and Lee, Wenke},
	editor = {Mattoso, Marta and Glavic, Boris},
	month = jun,
	year = {2016},
	note = {DOI: 10.1007/978-3-319-40593-3\_1},
	keywords = {Artificial Intelligence (incl. Robotics), Computers and Society, Database Management, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Management of Computing and Information Systems, PROV, Provenance capturing, Record and replay, User space},
	pages = {3--15},
	file = {Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/J8CIFBDR/10.html:text/html}
}



@inproceedings{park_provenance-based_2012,
	title = {A provenance-based access control model},
	doi = {10.1109/PST.2012.6297930},
	abstract = {Existence of data provenance information in a system raises at least two security-related issues. One is how provenance data can be used to enhance security in the system and the other is how to protect provenance data which might be more sensitive than the data itself. Recent data provenance-related access control literature mainly focuses on the latter issue of protecting provenance data. In this paper, we propose a novel provenance-based access control model that addresses the former objective. Using provenance data for access control to the underlying data facilitates additional capabilities beyond those available in traditional access control models. We utilize a notion of dependency as the key foundation for access control policy specification. Dependency-based policy provides simplicity and effectiveness in policy specification and access control administration. We show our model can support dynamic separation of duty, workflow control, origin-based control, and object versioning. The proposed model identifies essential components and concepts and provides a foundational base model for provenance-based access control. We further discuss possible extensions of the proposed base model for enhanced access controls.},
	booktitle = {2012 {Tenth} {Annual} {International} {Conference} on {Privacy}, {Security} and {Trust} ({PST})},
	author = {Park, J. and Nguyen, D. and Sandhu, R.},
	month = jul,
	year = {2012},
	keywords = {access control administration, access control policy specification, authorisation, Authorization, Computational modeling, Data models, data provenance information, dependency-based policy, dependency notion, dynamic duty separation, Grammar, History, information science, object versioning, origin-based control, provenance-based access control model, provenance data protection, security enhancement, workflow control},
	pages = {137--144},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/5R5269ZN/6297930.html:text/html}
}

@inproceedings{ledlie_provenance-aware_2005,
	title = {Provenance-{Aware} {Sensor} {Data} {Storage}},
	doi = {10.1109/ICDE.2005.270},
	abstract = {Sensor network data has both historical and realtime value. Making historical sensor data useful, in particular, requires storage, naming, and indexing. Sensor data presents new challenges in these areas. Such data is location-specific but also distributed; it is collected in a particular physical location and may be most useful there, but it has additional value when combined with other sensor data collections in a larger distributed system. Thus, arranging location-sensitive peer-to-peer storage is one challenge. Sensor data sets do not have obvious names, so naming them in a globally useful fashion is another challenge. The last challenge arises from the need to index these sensor data sets to make them searchable. The key to sensor data identity is provenance, the full history or lineage of the data. We show how provenance addresses the naming and indexing issues and then present a research agenda for constructing distributed, indexed repositories of sensor data.},
	booktitle = {21st {International} {Conference} on {Data} {Engineering} {Workshops} ({ICDEW}'05)},
	author = {Ledlie, J. and Ng, Chaki and Holland, D. A.},
	month = apr,
	year = {2005},
	keywords = {Biosensors, Data engineering, History, Indexing, Memory, Monitoring, Peer to peer computing, Sensor phenomena and characterization, Sensor systems, Telecommunication traffic},
	pages = {1189--1189},
	file = {IEEE Xplore Abstract Record:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/78NNNMZW/1647801.html:text/html}
}

@inproceedings{_general-purpose_2012,
	title = {A {General}-{Purpose} {Provenance} {Library}},
	url = {https://www.usenix.org/conference/tapp12/workshop-program/presentation/macko},
	urldate = {2016-09-15},
	year = {2012},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/GXEPA4VM/2012 - A General-Purpose Provenance Library.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/EDAXEQDA/macko.html:text/html}
}

@article{seltzer_collecting_2011,
	title = {Collecting {Provenance} via the {Xen} {Hypervisor}},
	copyright = {open},
	url = {https://dash.harvard.edu/handle/1/5168855},
	abstract = {The Provenance Aware Storage Systems project (PASS) currently collects system-level provenance by intercepting system calls in the Linux kernel and storing the provenance in a stackable ﬁlesystem. While this approach is reasonably efﬁcient, it suffers from two signiﬁcant drawbacks: each new revision of the kernel requires reintegration of PASS changes, the stability of which must be continually tested; also, the use of a stackable ﬁlesystem makes it difﬁcult to collect provenance
on root volumes, especially during early boot. In this paper we describe an approach to collecting system-level provenance from virtual guest machines running under the Xen hypervisor. We make the case that our approach alleviates the aforementioned difﬁculties and promotes adoption of provenance collection within cloud computing platforms.},
	language = {en\_US},
	urldate = {2016-09-15},
	author = {Seltzer, Margo I. and Macko, Peter and Chiarini, Marc A.},
	year = {2011},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/G8GBG7UC/Seltzer et al. - 2011 - Collecting Provenance via the Xen Hypervisor.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/RRHHDJVR/5168855.html:text/html}
}

@inproceedings{bates_trustworthy_2015,
	title = {Trustworthy {Whole}-{System} {Provenance} for the {Linux} {Kernel}},
	isbn = {978-1-931971-23-2},
	url = {https://www.usenix.org/node/190901},
	urldate = {2016-09-15},
	author = {Bates, Adam and Tian, Dave (Jing) and Butler, Kevin R. B. and Moyer, Thomas},
	year = {2015},
	pages = {319--334},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/UDQT8XGS/Bates et al. - 2015 - Trustworthy Whole-System Provenance for the Linux .pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/FJVHD8KK/190901.html:text/html}
}

@inproceedings{pohly_hi-fi:_2012,
	address = {New York, NY, USA},
	series = {{ACSAC} '12},
	title = {Hi-{Fi}: {Collecting} {High}-fidelity {Whole}-system {Provenance}},
	isbn = {978-1-4503-1312-4},
	shorttitle = {Hi-{Fi}},
	url = {http://doi.acm.org/10.1145/2420950.2420989},
	doi = {10.1145/2420950.2420989},
	abstract = {Data provenance---a record of the origin and evolution of data in a system---is a useful tool for forensic analysis. However, existing provenance collection mechanisms fail to achieve sufficient breadth or fidelity to provide a holistic view of a system's operation over time. We present Hi-Fi, a kernel-level provenance system which leverages the Linux Security Modules framework to collect high-fidelity whole-system provenance. We demonstrate that Hi-Fi is able to record a variety of malicious behavior within a compromised system. In addition, our benchmarks show the collection overhead from Hi-Fi to be less than 1\% for most system calls and 3\% in a representative workload, while simultaneously generating a system measurement that fully reflects system evolution. In this way, we show that we can collect broad, high-fidelity provenance data which is capable of supporting detailed forensic analysis.},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the 28th {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher = {ACM},
	author = {Pohly, Devin J. and McLaughlin, Stephen and McDaniel, Patrick and Butler, Kevin},
	year = {2012},
	keywords = {data provenance, forensics, malware, reference monitor},
	pages = {259--268}
}

@incollection{gessiou_towards_2012,
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Towards a {Universal} {Data} {Provenance} {Framework} {Using} {Dynamic} {Instrumentation}},
	copyright = {©2012 IFIP International Federation for Information Processing},
	isbn = {978-3-642-30435-4 978-3-642-30436-1},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-30436-1_9},
	abstract = {The advantage of collecting data provenance information has driven research on how to extend or modify applications and systems in order to provide it, or the creation of architectures that are built from the ground up with provenance capabilities. In this paper we propose a universal data provenance framework, using dynamic instrumentation, which gathers data provenance information for real-world applications without any code modifications. Our framework simplifies the task of finding the right points to instrument, which can be cumbersome in large and complex systems. We have built a proof-of-concept implementation of the framework on top of DTrace. Moreover, we evaluated its functionality by using it for three different scenarios: file-system operations, database transactions and web browser HTTP requests. Based on our experiences we believe that it is possible to provide data provenance, transparently, to any layer of the software stack.},
	language = {en},
	number = {376},
	urldate = {2016-09-15},
	booktitle = {Information {Security} and {Privacy} {Research}},
	publisher = {Springer Berlin Heidelberg},
	author = {Gessiou, Eleni and Pappas, Vasilis and Athanasopoulos, Elias and Keromytis, Angelos D. and Ioannidis, Sotiris},
	editor = {Gritzalis, Dimitris and Furnell, Steven and Theoharidou, Marianthi},
	month = jun,
	year = {2012},
	note = {DOI: 10.1007/978-3-642-30436-1\_9},
	keywords = {Algorithm Analysis and Problem Complexity, Computer Communication Networks, Computers and Society, Data Encryption, Information Systems Applications (incl. Internet), Management of Computing and Information Systems},
	pages = {103--114},
	file = {Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/F92G29MF/Gessiou et al. - 2012 - Towards a Universal Data Provenance Framework Usin.pdf:application/pdf;Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/2HF79I6R/978-3-642-30436-1_9.html:text/html}
}

@inproceedings{spillane_story_2009,
	address = {Berkeley, CA, USA},
	series = {{TAPP}'09},
	title = {Story {Book}: {An} {Efficient} {Extensible} {Provenance} {Framework}},
	shorttitle = {Story {Book}},
	url = {http://dl.acm.org/citation.cfm?id=1525932.1525943},
	abstract = {Most application provenance systems are hard coded for a particular type of system or data, while current provenance file systems maintain in-memory provenance graphs and reside in kernel space, leading to complex and constrained implementations. Story Book resides in user space, and treats provenance events as a generic event log, leading to a simple, flexible and easily optimized system. We demonstrate the flexibility of our design by adding provenance to a number of different systems, including a file system, database and a number of file types, and by implementing two separate storage backends. Although Story Book is nearly 2.5 times slower than ext3 under worst case workloads, this is mostly due to FUSE message passing overhead. Our experiments show that coupling our simple design with existing storage optimizations provides higher throughput than existing systems.},
	urldate = {2016-09-15},
	booktitle = {First {Workshop} on on {Theory} and {Practice} of {Provenance}},
	publisher = {USENIX Association},
	author = {Spillane, R. and Sears, R. and Yalamanchili, C. and Gaikwad, S. and Chinni, M. and Zadok, E.},
	year = {2009},
	pages = {11:1--11:10}
}

@inproceedings{tariq_towards_2012,
	address = {Berkeley, CA, USA},
	series = {{TaPP}'12},
	title = {Towards {Automated} {Collection} of {Application}-level {Data} {Provenance}},
	url = {http://dl.acm.org/citation.cfm?id=2342875.2342891},
	abstract = {Gathering data provenance at the operating system level is useful for capturing system-wide activity. However, many modern programs are complex and can perform numerous tasks concurrently. Capturing their provenance at this level, where processes are treated as single entities, may lead to the loss of useful intra-process detail. This can, in turn, produce false dependencies in the provenance graph. Using the LLVM compiler framework and SPADE provenance infrastructure, we investigate adding provenance instrumentation to allow intraprocess provenance to be captured automatically. This results in a more accurate representation of the provenance relationships and eliminates some false dependencies. Since the capture of fine-grained provenance incurs increased overhead for storage and querying, we minimize the records retained by allowing users to declare aspects of interest and then automatically infer which provenance records are unnecessary and can be discarded.},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the 4th {USENIX} {Conference} on {Theory} and {Practice} of {Provenance}},
	publisher = {USENIX Association},
	author = {Tariq, Dawood and Ali, Maisem and Gehani, Ashish},
	year = {2012},
	pages = {16--16}
}

@inproceedings{ghoshal_provenance_2013,
	address = {New York, NY, USA},
	series = {{EDBT} '13},
	title = {Provenance from {Log} {Files}: {A} {BigData} {Problem}},
	isbn = {978-1-4503-1599-9},
	shorttitle = {Provenance from {Log} {Files}},
	url = {http://doi.acm.org/10.1145/2457317.2457366},
	doi = {10.1145/2457317.2457366},
	urldate = {2016-09-15},
	booktitle = {Proceedings of the {Joint} {EDBT}/{ICDT} 2013 {Workshops}},
	publisher = {ACM},
	author = {Ghoshal, Devarshi and Plale, Beth},
	year = {2013},
	pages = {290--297}
}

@article{hussain_secure_2014,
	title = {Secure {Data} {Provenance} {Compression} {Using} {Arithmetic} {Coding} in {Wireless} {Sensor} {Networks}},
	url = {http://docs.lib.purdue.edu/ccpubs/645},
	doi = {10.1109/PCCC.2014.7017068},
	journal = {2014 IEEE International Performance Computing and Communications Conference (IPCCC)},
	author = {Hussain, Syed Rafiul and Wang, Changda and Sultana, Salmin and Bertino, Elisa},
	month = dec,
	year = {2014},
	file = {"Secure Data Provenance Compression Using Arithmetic Coding in Wireless" by Syed Rafiul Hussain, Changda Wang et al.:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/PD6237WV/645.html:text/html}
}

@inproceedings{muniswamy-reddy_provenance-aware_2006,
	address = {Berkeley, CA, USA},
	series = {{ATEC} '06},
	title = {Provenance-aware {Storage} {Systems}},
	url = {http://dl.acm.org/citation.cfm?id=1267359.1267363},
	abstract = {A Provenance-Aware Storage System (PASS) is a storage system that automatically collects and maintains provenance or lineage, the complete history or ancestry of an item. We discuss the advantages of treating provenance as meta-data collected and maintained by the storage system, rather than as manual annotations stored in a separately administered database. We describe a PASS implementation, discussing the challenges it presents, performance cost it incurs, and the new functionality it enables. We show that with reasonable overhead, we can provide useful functionality not available in today's file systems or provenance management systems.},
	urldate = {2016-09-16},
	booktitle = {Proceedings of the {Annual} {Conference} on {USENIX} '06 {Annual} {Technical} {Conference}},
	publisher = {USENIX Association},
	author = {Muniswamy-Reddy, Kiran-Kumar and Holland, David A. and Braun, Uri and Seltzer, Margo},
	year = {2006},
	pages = {4--4}
}

@inproceedings{groth_preserv:_????,
	title = {{PReServ}: {Provenance} recording for services},
	shorttitle = {{PReServ}},
	abstract = {The importance of understanding the process by which a result was generated in an experiment is fundamental to science. Without such information, other scientists cannot replicate, validate, or duplicate an experiment. We define provenance as the process that led to a result. With large scale in-silico experiments, it becomes increasingly difficult for scientists to record process documentation that can be used to retrieve the provenance of a result. Provenance Recording for Services (PReServ) is a software package that allows developers to integrate process documentation recording into their applications. PReServ has been used by several applications and its performance has been benchmarked. 1},
	booktitle = {in {Proc}. {AHM}’05},
	author = {Groth, Paul and Miles, Simon and Moreau, Luc},
	file = {Citeseer - Full Text PDF:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/FE2DFP4Z/Groth et al. - PReServ Provenance recording for services.pdf:application/pdf;Citeseer - Snapshot:/Users/ebelechukwu/Library/Application Support/Zotero/Profiles/17a8i7ac.default/zotero/storage/JUTMJJST/summary.html:text/html}
}

@article{cheney_provenance_2009,
	title = {Provenance in {Databases}: {Why}, {How}, and {Where}},
	volume = {1},
	issn = {1931-7883},
	shorttitle = {Provenance in {Databases}},
	url = {http://dx.doi.org/10.1561/1900000006},
	doi = {10.1561/1900000006},
	abstract = {Different notions of provenance for database queries have been proposed and studied in the past few years. In this article, we detail three main notions of database provenance, some of their applications, and compare and contrast amongst them. Specifically, we review why, how, and where provenance, describe the relationships among these notions of provenance, and describe some of their applications in confidence computation, view maintenance and update, debugging, and annotation propagation.},
	number = {4},
	urldate = {2016-09-16},
	journal = {Found. Trends databases},
	author = {Cheney, James and Chiticariu, Laura and Tan, Wang-Chiew},
	month = apr,
	year = {2009},
	pages = {379--474}
}

@inproceedings{muniswamy-reddy_provenance_2010,
	address = {Berkeley, CA, USA},
	series = {{FAST}'10},
	title = {Provenance for the {Cloud}},
	url = {http://dl.acm.org/citation.cfm?id=1855511.1855526},
	abstract = {The cloud is poised to become the next computing environment for both data storage and computation due to its pay-as-you-go and provision-as-you-go models. Cloud storage is already being used to back up desktop user data, host shared scientific data, store web application data, and to serve web pages. Today's cloud stores, however, are missing an important ingredient: provenance. Provenance is metadata that describes the history of an object. We make the case that provenance is crucial for data stored on the cloud and identify the properties of provenance that enable its utility. We then examine current cloud offerings and design and implement three protocols for maintaining data/provenance in current cloud stores. The protocols represent different points in the design space and satisfy different subsets of the provenance properties. Our evaluation indicates that the overheads of all three protocols are comparable to each other and reasonable in absolute terms. Thus, one can select a protocol based upon the properties it provides without sacrificing performance. While it is feasible to provide provenance as a layer on top of today's cloud offerings, we conclude by presenting the case for incorporating provenance as a core cloud feature, discussing the issues in doing so.},
	urldate = {2016-09-16},
	booktitle = {Proceedings of the 8th {USENIX} {Conference} on {File} and {Storage} {Technologies}},
	publisher = {USENIX Association},
	author = {Muniswamy-Reddy, Kiran-Kumar and Macko, Peter and Seltzer, Margo},
	year = {2010},
	pages = {15--14}
}

@incollection{glavic_case_2011,
	title = {The {Case} for {Fine}-{Grained} {Stream} {Provenance}},
	url = {http://cs.iit.edu/%7edbgroup/pdfpubls/GE11.pdf},
	booktitle = {Proceedings of the 1st {Workshop} on {Data} {Streams} and {Event} {Processing} ({DSEP}) collocated with {BTW}},
	author = {Glavic, Boris and Esmaili, Kyumars Sheykh and Fischer, Peter M. and Tatbul, Nesime},
	year = {2011}
}